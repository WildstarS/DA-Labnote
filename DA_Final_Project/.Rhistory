MSE_df1_gam2
X_df1 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn1)[,-1]
y_df1 <- trn1$y
Xtst_df1 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = tst1)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df1, y_df1, alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df1 <- glmnet(X_df1, y_df1, alpha = 1, lambda = bestlambda)
lasso_df1
MSE_df1_lasso <- mean((predict.glmnet(lasso_df1, Xtst_df1) - tst1$y)^2)
MSE_df1_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df1, y_df1, alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df1 <- glmnet(X_df1, y_df1, alpha = 0, lambda = bestlambda)
ridge_df1
MSE_df1_ridge <- mean((predict(ridge_df1, Xtst_df1) - tst1$y)^2)
MSE_df1_ridge
MSE_df1_lm1
MSE_df1_lm2
MSE_df1_lm3
MSE_df1_gam1
MSE_df1_gam2
MSE_df1_ridge
MSE_df1_lasso
final_csv[,2] <- predict(gam2_df1, newdata = df1_test)
df2_train <- read.csv("./dataset/dataset2_train.csv")
df2_test <- read.csv("./dataset/dataset2_test.csv")
df2_train
summary(df2_train)
sum(df2_train$y)/800
ggcorrplot(cor(df2_train), lab = T, lab_size = 2)
set.seed(42)
data_split_df2 <- initial_split(df2_train, prop = 0.9)
trn2 <- training(data_split_df2)
tst2 <- testing(data_split_df2)
pairs(~x2 + x4 + x5 + x6 + x10 + y, data = trn2)
X_df2 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn2)[,-1]
y_df2 <- trn2$y
Xtst_df2 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = tst2)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df2, y_df2, family = 'binomial', alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df2 <- glmnet(X_df2, y_df2, family = 'binomial', alpha = 1, lambda = bestlambda)
lasso_df2
coef(lasso_df2)
pred <- ifelse(predict(lasso_df2, newx = Xtst_df2, type = "response") > 0.5, 1, 0)
MSE_df2_lasso <- mean(pred - tst2$y)^2
MSE_df2_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df2, y_df2, family = 'binomial', alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df2 <- glmnet(X_df2, y_df2, family = 'binomial', alpha = 0, lambda = bestlambda)
ridge_df2
pred <- ifelse(predict(ridge_df2, newx = Xtst_df2, type = "response") > 0.5, 1, 0)
MSE_df2_ridge <- mean(pred - tst2$y)^2
MSE_df2_ridge
NBayes1_df2 <- naiveBayes(y ~ x4 + x5 + x10, data = trn2)
NBayes1_df2
MSE_df2_NBayes1 <- mean(as.numeric(predict(NBayes1_df2, tst2, type = "class"))-1-tst2$y)^2
NBayes2_df2 <- naiveBayes(y ~ x4 + x10, data = trn2)
NBayes2_df2
MSE_df2_NBayes2 <- mean(as.numeric(predict(NBayes2_df2, tst2, type = "class"))-1-tst2$y)^2
NBayes3_df2 <- naiveBayes(y ~ x4 + x5 + x6 + x10, data = trn2)
NBayes3_df2
MSE_df2_NBayes3 <- mean(as.numeric(predict(NBayes3_df2, tst2, type = "class"))-1-tst2$y)^2
for (i in 1:10) {
print(paste('Variance of x_', i, '=', var(df2_train)[i+1,i+1], sep = ''))
}
MSE_df2_lasso
MSE_df2_ridge
MSE_df2_NBayes1
MSE_df2_NBayes2
MSE_df2_NBayes3
final_csv[,3] <- as.numeric(predict(NBayes2_df2, df2_test, type = "class"))-1
df3_train <- read.csv("./dataset/dataset3_train.csv")
df3_test <- read.csv("./dataset/dataset3_test.csv")
df3_train
summary(df3_train)
pairs(~., data = df3_train)
hist(df3_train$y)
set.seed(42)
data_split_df3 <- initial_split(df3_train, prop = 0.9)
trn3 <- training(data_split_df3)
tst3 <- testing(data_split_df3)
df3_train %>% filter(y > 10)
trn3_drop <- trn3 %>% filter(y < 7.4)
best_select_df3 <- regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn3, nvmax = 10)
sum_lm3 <- summary(best_select_df3)
which.min(sum_lm3$cp)
which.min(sum_lm3$bic)
which.min(sum_lm3$adjr2)
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn3, nvmax = 10), id = 1)
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn3, nvmax = 10), id = 2)
ggcorrplot(cor(trn3), lab = T, lab_size = 2)
pairs(~x6 + x10 + y, data = trn3)
pairs(~x6 + x10 + y, data = trn3_drop)
lm1_df3 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x6, data = trn3)
MSE_df3_lm1 <- mean(pluck((predict(lm1_df3, tst3) - tst3$y)^2, 1))
MSE_df3_lm1
lm2_df3 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x6 + x10, data = trn3)
MSE_df3_lm2 <- mean(pluck((predict(lm2_df3, tst3) - tst3$y)^2, 1))
MSE_df3_lm2
gam1_df3 <- gam(y ~ ns(x6), data = trn3)
summary(gam1_df3)
gam2_df3 <- gam(y ~ ns(x6) + ns(x10), data = trn3)
summary(gam2_df3)
gam1_df3.drop <- gam(y ~ ns(x6), data = trn3_drop)
summary(gam1_df3.drop)
gam2_df3.drop <- gam(y ~ ns(x6) + ns(x10), data = trn3_drop)
summary(gam2_df3.drop)
MSE_df3_gam1 <- mean(pluck((predict(gam1_df3, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam1.drop <- mean(pluck((predict(gam1_df3.drop, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam2 <- mean(pluck((predict(gam2_df3, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam2.drop <- mean(pluck((predict(gam2_df3.drop, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam1
MSE_df3_gam1.drop
MSE_df3_gam2
MSE_df3_gam2.drop
X_df3 <- model.matrix(y ~ x6 + x10, data = trn3)[,-1]
y_df3 <- trn3$y
Xtst_df3 <- model.matrix(y ~ x6 + x10, data = tst3)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df3, y_df3, alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df3 <- glmnet(X_df3, y_df3, alpha = 1, lambda = bestlambda)
summary(lasso_df3)
MSE_df3_lasso <- mean((predict(lasso_df3, Xtst_df3) - tst3$y)^2)
MSE_df3_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df3, y_df3, alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df3 <- glmnet(X_df3, y_df3, alpha = 0, lambda = bestlambda)
summary(ridge_df3)
MSE_df3_ridge <- mean((predict.glmnet(ridge_df3, Xtst_df3) - tst3$y)^2)
MSE_df3_ridge
MSE_df3_lm1
MSE_df3_lm2
MSE_df3_gam1
MSE_df3_gam1.drop
MSE_df3_gam2
MSE_df3_gam2.drop
MSE_df3_ridge
MSE_df3_lasso
testX <- model.matrix(~ x6 + x10, data = df3_test)[,-1]
final_csv[,4] <- predict(lasso_df3, newx = testX)[,1]
df4_train <- read.csv("./dataset/dataset4_train.csv")
df4_test <- read.csv("./dataset/dataset4_test.csv")
df4_train
summary(df4_train$y)
ggcorrplot(cor(df4_train), lab = T, lab_size = 2)
set.seed(42)
data_split_df4 <- initial_split(df4_train, prop = 0.9)
trn4 <- training(data_split_df4)
tst4 <- testing(data_split_df4)
pairs(~x6 + x7 + x8 + x9 + x10 + y, data = trn4)
best_select_df4 <- regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn4, nvmax = 10)
sum_lm4 <- summary(best_select_df4)
which.min(sum_lm4$cp)
which.min(sum_lm4$bic)
which.min(sum_lm4$adjr2)
coef(best_select_df4, id = 1)
coef(best_select_df4, id = 3)
lm1_df4 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x9, data = trn4)
MSE_df4_lm1 <- mean(pluck((predict(lm1_df4, tst4) - tst4$y)^2, 1))
MSE_df4_lm1
lm2_df4 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x5 + x7 + x9, data = trn4)
MSE_df4_lm2 <- mean(pluck((predict(lm2_df4, tst4) - tst4$y)^2, 1))
MSE_df4_lm2
gam1_df4 <- gam(y ~ ns(x9), data = trn4)
summary(gam1_df4)
gam2_df4 <- gam(y ~ ns(x5) + ns(x7) + ns(x9), data = trn4)
summary(gam2_df4)
gam3_df4 <- gam(y ~ ns(x5) + ns(x7) + x9, data = trn4)
summary(gam3_df4)
MSE_df4_gam1 <- mean(pluck((predict(gam1_df4, newdata = tst4) - tst4$y)^2, 1))
MSE_df4_gam1
MSE_df4_gam2 <- mean(pluck((predict(gam2_df4, newdata = tst4) - tst4$y)^2, 1))
MSE_df4_gam2
MSE_df4_gam3 <- mean(pluck((predict(gam3_df4, newdata = tst4) - tst4$y)^2, 1))
MSE_df4_gam3
X_df4 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn4)[,-1]
y_df4 <- trn4$y
Xtst_df4 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = tst4)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df4, y_df4, alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df4 <- glmnet(X_df4, y_df4, alpha = 1, lambda = bestlambda)
summary(lasso_df4)
MSE_df4_lasso <- mean((predict(lasso_df4, Xtst_df4) - tst4$y)^2)
MSE_df4_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df4, y_df4, alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df4 <- glmnet(X_df4, y_df4, alpha = 0, lambda = bestlambda)
summary(ridge_df4)
MSE_df4_ridge <- mean((predict.glmnet(ridge_df4, Xtst_df4) - tst4$y)^2)
MSE_df4_ridge
MSE_df4_lm1
MSE_df4_lm2
MSE_df4_gam1
MSE_df4_gam2
MSE_df4_gam3
MSE_df4_lasso
MSE_df4_ridge
testX <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = df4_test)[,-1]
knitr::opts_chunk$set(echo = TRUE)
library(tidymodels)#model learning
library(boot)
library(caret)
library(splines)#Splines
library(pscl)# zero-inflated models
library(ggcorrplot)# for corrplot
library(e1071)#naive bayse
library(MASS)#lda, qda
library(tidyverse)
library(leaps)#linear model selection
library(gam)
library(glmnet)
library(klaR)
final_csv <- read.csv("./dataset/test_prediction.csv")
colnames_final <- colnames(final_csv)
df1_train <- read.csv("./dataset/dataset1_train.csv")
df1_test <- read.csv("./dataset/dataset1_test.csv")
df1_train
summary(df1_train$y)
set.seed(42)
data_split_df1 <- initial_split(df1_train, prop = 0.9)
trn1 <- training(data_split_df1)
tst1 <- testing(data_split_df1)
best_select_df1 <- regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn1, nvmax = 10)
sum_lm1 <- summary(best_select_df1)
which.min(sum_lm1$cp)
which.min(sum_lm1$bic)
which.min(sum_lm1$adjr2)
pairs(~x2 + x5 + x7 + x9 + x10 + y, data = trn1)
pairs(~x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10 + y, data = trn1)
ggcorrplot(cor(trn1), lab = T, lab_size = 2)
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn1, nvmax = 10), id = 1)
lm1_df1 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x7, data = trn1)
MSE_df1_lm1 <- mean(pluck((predict(lm1_df1, tst1) - tst1$y)^2, 1))
MSE_df1_lm1
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn1, nvmax = 10), id = 4)
lm2_df1 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x2 + x5 + x7 + x9, data = trn1)
MSE_df1_lm2 <- mean(pluck((predict(lm2_df1, tst1) - tst1$y)^2, 1))
MSE_df1_lm2
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn1, nvmax = 10), id = 5)
lm3_df1 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x2 + x5 + x7 + x9 + x10, data = trn1)
MSE_df1_lm3 <- mean(pluck((predict(lm3_df1, tst1) - tst1$y)^2, 1))
MSE_df1_lm3
gam1_df1 <- gam(y ~ x2 + x5 + x7 + ns(x9), data = trn1)
gam2_df1 <- gam(y ~ x2 + x7 + ns(x9), data = trn1)
summary(gam1_df1)
summary(gam2_df1)
MSE_df1_gam1 <- mean(pluck((predict(gam1_df1, newdata = tst1) - tst1$y)^2, 1))
MSE_df1_gam1
MSE_df1_gam2 <- mean(pluck((predict(gam2_df1, newdata = tst1) - tst1$y)^2, 1))
MSE_df1_gam2
X_df1 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn1)[,-1]
y_df1 <- trn1$y
Xtst_df1 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = tst1)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df1, y_df1, alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df1 <- glmnet(X_df1, y_df1, alpha = 1, lambda = bestlambda)
lasso_df1
MSE_df1_lasso <- mean((predict.glmnet(lasso_df1, Xtst_df1) - tst1$y)^2)
MSE_df1_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df1, y_df1, alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df1 <- glmnet(X_df1, y_df1, alpha = 0, lambda = bestlambda)
ridge_df1
MSE_df1_ridge <- mean((predict(ridge_df1, Xtst_df1) - tst1$y)^2)
MSE_df1_ridge
MSE_df1_lm1
MSE_df1_lm2
MSE_df1_lm3
MSE_df1_gam1
MSE_df1_gam2
MSE_df1_ridge
MSE_df1_lasso
final_csv[,2] <- predict(gam2_df1, newdata = df1_test)
df2_train <- read.csv("./dataset/dataset2_train.csv")
df2_test <- read.csv("./dataset/dataset2_test.csv")
df2_train
summary(df2_train)
sum(df2_train$y)/800
ggcorrplot(cor(df2_train), lab = T, lab_size = 2)
set.seed(42)
data_split_df2 <- initial_split(df2_train, prop = 0.9)
trn2 <- training(data_split_df2)
tst2 <- testing(data_split_df2)
pairs(~x2 + x4 + x5 + x6 + x10 + y, data = trn2)
X_df2 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn2)[,-1]
y_df2 <- trn2$y
Xtst_df2 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = tst2)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df2, y_df2, family = 'binomial', alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df2 <- glmnet(X_df2, y_df2, family = 'binomial', alpha = 1, lambda = bestlambda)
lasso_df2
coef(lasso_df2)
pred <- ifelse(predict(lasso_df2, newx = Xtst_df2, type = "response") > 0.5, 1, 0)
MSE_df2_lasso <- mean(pred - tst2$y)^2
MSE_df2_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df2, y_df2, family = 'binomial', alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df2 <- glmnet(X_df2, y_df2, family = 'binomial', alpha = 0, lambda = bestlambda)
ridge_df2
pred <- ifelse(predict(ridge_df2, newx = Xtst_df2, type = "response") > 0.5, 1, 0)
MSE_df2_ridge <- mean(pred - tst2$y)^2
MSE_df2_ridge
NBayes1_df2 <- naiveBayes(y ~ x4 + x5 + x10, data = trn2)
NBayes1_df2
MSE_df2_NBayes1 <- mean(as.numeric(predict(NBayes1_df2, tst2, type = "class"))-1-tst2$y)^2
NBayes2_df2 <- naiveBayes(y ~ x4 + x10, data = trn2)
NBayes2_df2
MSE_df2_NBayes2 <- mean(as.numeric(predict(NBayes2_df2, tst2, type = "class"))-1-tst2$y)^2
NBayes3_df2 <- naiveBayes(y ~ x4 + x5 + x6 + x10, data = trn2)
NBayes3_df2
MSE_df2_NBayes3 <- mean(as.numeric(predict(NBayes3_df2, tst2, type = "class"))-1-tst2$y)^2
for (i in 1:10) {
print(paste('Variance of x_', i, '=', var(df2_train)[i+1,i+1], sep = ''))
}
MSE_df2_lasso
MSE_df2_ridge
MSE_df2_NBayes1
MSE_df2_NBayes2
MSE_df2_NBayes3
final_csv[,3] <- as.numeric(predict(NBayes2_df2, df2_test, type = "class"))-1
df3_train <- read.csv("./dataset/dataset3_train.csv")
df3_test <- read.csv("./dataset/dataset3_test.csv")
df3_train
summary(df3_train)
pairs(~., data = df3_train)
hist(df3_train$y)
set.seed(42)
data_split_df3 <- initial_split(df3_train, prop = 0.9)
trn3 <- training(data_split_df3)
tst3 <- testing(data_split_df3)
df3_train %>% filter(y > 10)
trn3_drop <- trn3 %>% filter(y < 7.4)
best_select_df3 <- regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn3, nvmax = 10)
sum_lm3 <- summary(best_select_df3)
which.min(sum_lm3$cp)
which.min(sum_lm3$bic)
which.min(sum_lm3$adjr2)
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn3, nvmax = 10), id = 1)
coef(regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn3, nvmax = 10), id = 2)
ggcorrplot(cor(trn3), lab = T, lab_size = 2)
pairs(~x6 + x10 + y, data = trn3)
pairs(~x6 + x10 + y, data = trn3_drop)
lm1_df3 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x6, data = trn3)
MSE_df3_lm1 <- mean(pluck((predict(lm1_df3, tst3) - tst3$y)^2, 1))
MSE_df3_lm1
lm2_df3 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x6 + x10, data = trn3)
MSE_df3_lm2 <- mean(pluck((predict(lm2_df3, tst3) - tst3$y)^2, 1))
MSE_df3_lm2
gam1_df3 <- gam(y ~ ns(x6), data = trn3)
summary(gam1_df3)
gam2_df3 <- gam(y ~ ns(x6) + ns(x10), data = trn3)
summary(gam2_df3)
gam1_df3.drop <- gam(y ~ ns(x6), data = trn3_drop)
summary(gam1_df3.drop)
gam2_df3.drop <- gam(y ~ ns(x6) + ns(x10), data = trn3_drop)
summary(gam2_df3.drop)
MSE_df3_gam1 <- mean(pluck((predict(gam1_df3, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam1.drop <- mean(pluck((predict(gam1_df3.drop, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam2 <- mean(pluck((predict(gam2_df3, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam2.drop <- mean(pluck((predict(gam2_df3.drop, newdata = tst3) - tst3$y)^2, 1))
MSE_df3_gam1
MSE_df3_gam1.drop
MSE_df3_gam2
MSE_df3_gam2.drop
X_df3 <- model.matrix(y ~ x6 + x10, data = trn3)[,-1]
y_df3 <- trn3$y
Xtst_df3 <- model.matrix(y ~ x6 + x10, data = tst3)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df3, y_df3, alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df3 <- glmnet(X_df3, y_df3, alpha = 1, lambda = bestlambda)
summary(lasso_df3)
MSE_df3_lasso <- mean((predict(lasso_df3, Xtst_df3) - tst3$y)^2)
MSE_df3_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df3, y_df3, alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df3 <- glmnet(X_df3, y_df3, alpha = 0, lambda = bestlambda)
summary(ridge_df3)
MSE_df3_ridge <- mean((predict.glmnet(ridge_df3, Xtst_df3) - tst3$y)^2)
MSE_df3_ridge
MSE_df3_lm1
MSE_df3_lm2
MSE_df3_gam1
MSE_df3_gam1.drop
MSE_df3_gam2
MSE_df3_gam2.drop
MSE_df3_ridge
MSE_df3_lasso
testX <- model.matrix(~ x6 + x10, data = df3_test)[,-1]
final_csv[,4] <- predict(lasso_df3, newx = testX)[,1]
df4_train <- read.csv("./dataset/dataset4_train.csv")
df4_test <- read.csv("./dataset/dataset4_test.csv")
df4_train
summary(df4_train$y)
ggcorrplot(cor(df4_train), lab = T, lab_size = 2)
set.seed(42)
data_split_df4 <- initial_split(df4_train, prop = 0.9)
trn4 <- training(data_split_df4)
tst4 <- testing(data_split_df4)
pairs(~x6 + x7 + x8 + x9 + x10 + y, data = trn4)
best_select_df4 <- regsubsets(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn4, nvmax = 10)
sum_lm4 <- summary(best_select_df4)
which.min(sum_lm4$cp)
which.min(sum_lm4$bic)
which.min(sum_lm4$adjr2)
coef(best_select_df4, id = 1)
coef(best_select_df4, id = 3)
lm1_df4 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x9, data = trn4)
MSE_df4_lm1 <- mean(pluck((predict(lm1_df4, tst4) - tst4$y)^2, 1))
MSE_df4_lm1
lm2_df4 <-
linear_reg() %>%
set_engine('lm') %>%
fit(y ~ x5 + x7 + x9, data = trn4)
MSE_df4_lm2 <- mean(pluck((predict(lm2_df4, tst4) - tst4$y)^2, 1))
MSE_df4_lm2
gam1_df4 <- gam(y ~ ns(x9), data = trn4)
summary(gam1_df4)
gam2_df4 <- gam(y ~ ns(x5) + ns(x7) + ns(x9), data = trn4)
summary(gam2_df4)
gam3_df4 <- gam(y ~ ns(x5) + ns(x7) + x9, data = trn4)
summary(gam3_df4)
MSE_df4_gam1 <- mean(pluck((predict(gam1_df4, newdata = tst4) - tst4$y)^2, 1))
MSE_df4_gam1
MSE_df4_gam2 <- mean(pluck((predict(gam2_df4, newdata = tst4) - tst4$y)^2, 1))
MSE_df4_gam2
MSE_df4_gam3 <- mean(pluck((predict(gam3_df4, newdata = tst4) - tst4$y)^2, 1))
MSE_df4_gam3
X_df4 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = trn4)[,-1]
y_df4 <- trn4$y
Xtst_df4 <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = tst4)[,-1]
set.seed(42)
cv.out <- cv.glmnet(X_df4, y_df4, alpha = 1, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
lasso_df4 <- glmnet(X_df4, y_df4, alpha = 1, lambda = bestlambda)
summary(lasso_df4)
MSE_df4_lasso <- mean((predict(lasso_df4, Xtst_df4) - tst4$y)^2)
MSE_df4_lasso
set.seed(42)
cv.out <- cv.glmnet(X_df4, y_df4, alpha = 0, nfolds = 8)
bestlambda <- cv.out$lambda.min
bestlambda
ridge_df4 <- glmnet(X_df4, y_df4, alpha = 0, lambda = bestlambda)
summary(ridge_df4)
MSE_df4_ridge <- mean((predict.glmnet(ridge_df4, Xtst_df4) - tst4$y)^2)
MSE_df4_ridge
MSE_df4_lm1
MSE_df4_lm2
MSE_df4_gam1
MSE_df4_gam2
MSE_df4_gam3
MSE_df4_lasso
MSE_df4_ridge
testX <- model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9 + x10, data = df4_test)[,-1]
